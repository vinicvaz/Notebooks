{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/vinicius/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train.json')\n",
    "test = pd.read_json('./data/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF lenght: 4040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "giver_username_if_known                                    0\n",
       "number_of_downvotes_of_request_at_retrieval                0\n",
       "number_of_upvotes_of_request_at_retrieval                  0\n",
       "post_was_edited                                            0\n",
       "request_id                                                 0\n",
       "request_number_of_comments_at_retrieval                    0\n",
       "request_text                                               0\n",
       "request_text_edit_aware                                    0\n",
       "request_title                                              0\n",
       "requester_account_age_in_days_at_request                   0\n",
       "requester_account_age_in_days_at_retrieval                 0\n",
       "requester_days_since_first_post_on_raop_at_request         0\n",
       "requester_days_since_first_post_on_raop_at_retrieval       0\n",
       "requester_number_of_comments_at_request                    0\n",
       "requester_number_of_comments_at_retrieval                  0\n",
       "requester_number_of_comments_in_raop_at_request            0\n",
       "requester_number_of_comments_in_raop_at_retrieval          0\n",
       "requester_number_of_posts_at_request                       0\n",
       "requester_number_of_posts_at_retrieval                     0\n",
       "requester_number_of_posts_on_raop_at_request               0\n",
       "requester_number_of_posts_on_raop_at_retrieval             0\n",
       "requester_number_of_subreddits_at_request                  0\n",
       "requester_received_pizza                                   0\n",
       "requester_subreddits_at_request                            0\n",
       "requester_upvotes_minus_downvotes_at_request               0\n",
       "requester_upvotes_minus_downvotes_at_retrieval             0\n",
       "requester_upvotes_plus_downvotes_at_request                0\n",
       "requester_upvotes_plus_downvotes_at_retrieval              0\n",
       "requester_user_flair                                    3046\n",
       "requester_username                                         0\n",
       "unix_timestamp_of_request                                  0\n",
       "unix_timestamp_of_request_utc                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DF lenght:\",len(train))\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Many NULL values on \"requester_user_flair\"**\n",
    "\n",
    "Definition: Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \"shroom\" (received pizza, but not given, N=1306), or \"PIF\" (pizza given after having received, N=83)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['requester_user_flair'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3753"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['giver_username_if_known']=='N/A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To many N/A values on \"giver_username_if_known\" will drop this column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('giver_username_if_known',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4040 entries, 0 to 4039\n",
      "Data columns (total 30 columns):\n",
      "number_of_downvotes_of_request_at_retrieval             4040 non-null int64\n",
      "number_of_upvotes_of_request_at_retrieval               4040 non-null int64\n",
      "post_was_edited                                         4040 non-null int64\n",
      "request_id                                              4040 non-null object\n",
      "request_number_of_comments_at_retrieval                 4040 non-null int64\n",
      "request_text                                            4040 non-null object\n",
      "request_text_edit_aware                                 4040 non-null object\n",
      "request_title                                           4040 non-null object\n",
      "requester_account_age_in_days_at_request                4040 non-null float64\n",
      "requester_account_age_in_days_at_retrieval              4040 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_request      4040 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_retrieval    4040 non-null float64\n",
      "requester_number_of_comments_at_request                 4040 non-null int64\n",
      "requester_number_of_comments_at_retrieval               4040 non-null int64\n",
      "requester_number_of_comments_in_raop_at_request         4040 non-null int64\n",
      "requester_number_of_comments_in_raop_at_retrieval       4040 non-null int64\n",
      "requester_number_of_posts_at_request                    4040 non-null int64\n",
      "requester_number_of_posts_at_retrieval                  4040 non-null int64\n",
      "requester_number_of_posts_on_raop_at_request            4040 non-null int64\n",
      "requester_number_of_posts_on_raop_at_retrieval          4040 non-null int64\n",
      "requester_number_of_subreddits_at_request               4040 non-null int64\n",
      "requester_received_pizza                                4040 non-null bool\n",
      "requester_subreddits_at_request                         4040 non-null object\n",
      "requester_upvotes_minus_downvotes_at_request            4040 non-null int64\n",
      "requester_upvotes_minus_downvotes_at_retrieval          4040 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_request             4040 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_retrieval           4040 non-null int64\n",
      "requester_username                                      4040 non-null object\n",
      "unix_timestamp_of_request                               4040 non-null int64\n",
      "unix_timestamp_of_request_utc                           4040 non-null int64\n",
      "dtypes: bool(1), float64(4), int64(19), object(6)\n",
      "memory usage: 919.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Request ID (object columns with probably no value)\n",
    "train.drop('request_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop request raw text, will use request_text_edit_aware to predict\n",
    "train.drop(['request_text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop requester_subreddits_at_request and username\n",
    "train.drop(['requester_subreddits_at_request','requester_username'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have two object data, they are:  \n",
    "1.request_text_edit_aware  \n",
    "2.request_title**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename text and title columns\n",
    "train.rename(columns={\n",
    "    'request_text_edit_aware':'text',\n",
    "    'request_title':'title'  \n",
    "},inplace=True)\n",
    "\n",
    "## Rename text and title columns\n",
    "test.rename(columns={\n",
    "    'request_text_edit_aware':'text',\n",
    "    'request_title':'title'  \n",
    "},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to clean text (stopwords, punct and stemming)\n",
    "\n",
    "def clean(text):\n",
    "    sw = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    no_punc = text.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    no_punc = [word.lower() for word in no_punc.split() if word.lower() not in sw]\n",
    "    \n",
    "    no_stop = \" \".join(no_punc)\n",
    "    \n",
    "    stem = [stemmer.stem(word) for word in no_stop.split()]\n",
    "    \n",
    "    return \" \".join(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply cleaning function on text\n",
    "train['text'] = train['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply function on title\n",
    "train['title'] = train['title'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = train.drop('requester_received_pizza',axis=1)\n",
    "yt = train['requester_received_pizza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(xt['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4040, 9793), (4040,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.transform(xt['text']).todense()\n",
    "y = yt.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(n_estimators=500,learning_rate=0.003, num_leaves=2**6, subsample=0.75, subsample_freq=1, colsample_bytree=1,\n",
    "                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
       "               importance_type='split', learning_rate=0.003, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=64, objective=None,\n",
       "               random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.75, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.86       761\n",
      "        True       1.00      0.02      0.03       249\n",
      "\n",
      "    accuracy                           0.76      1010\n",
      "   macro avg       0.88      0.51      0.45      1010\n",
      "weighted avg       0.82      0.76      0.66      1010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = vectorizer.transform(test['text']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1631, 9793)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = test[['request_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_sub['requester_received_pizza'] = y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"first-submission-pizza.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
