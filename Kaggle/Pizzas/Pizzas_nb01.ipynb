{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/vinicius/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train.json')\n",
    "test = pd.read_json('./data/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF lenght: 4040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "giver_username_if_known                                    0\n",
       "number_of_downvotes_of_request_at_retrieval                0\n",
       "number_of_upvotes_of_request_at_retrieval                  0\n",
       "post_was_edited                                            0\n",
       "request_id                                                 0\n",
       "request_number_of_comments_at_retrieval                    0\n",
       "request_text                                               0\n",
       "request_text_edit_aware                                    0\n",
       "request_title                                              0\n",
       "requester_account_age_in_days_at_request                   0\n",
       "requester_account_age_in_days_at_retrieval                 0\n",
       "requester_days_since_first_post_on_raop_at_request         0\n",
       "requester_days_since_first_post_on_raop_at_retrieval       0\n",
       "requester_number_of_comments_at_request                    0\n",
       "requester_number_of_comments_at_retrieval                  0\n",
       "requester_number_of_comments_in_raop_at_request            0\n",
       "requester_number_of_comments_in_raop_at_retrieval          0\n",
       "requester_number_of_posts_at_request                       0\n",
       "requester_number_of_posts_at_retrieval                     0\n",
       "requester_number_of_posts_on_raop_at_request               0\n",
       "requester_number_of_posts_on_raop_at_retrieval             0\n",
       "requester_number_of_subreddits_at_request                  0\n",
       "requester_received_pizza                                   0\n",
       "requester_subreddits_at_request                            0\n",
       "requester_upvotes_minus_downvotes_at_request               0\n",
       "requester_upvotes_minus_downvotes_at_retrieval             0\n",
       "requester_upvotes_plus_downvotes_at_request                0\n",
       "requester_upvotes_plus_downvotes_at_retrieval              0\n",
       "requester_user_flair                                    3046\n",
       "requester_username                                         0\n",
       "unix_timestamp_of_request                                  0\n",
       "unix_timestamp_of_request_utc                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DF lenght:\",len(train))\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Many NULL values on \"requester_user_flair\"**\n",
    "\n",
    "Definition: Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \"shroom\" (received pizza, but not given, N=1306), or \"PIF\" (pizza given after having received, N=83)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['requester_user_flair'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3753"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['giver_username_if_known']=='N/A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To many N/A values on \"giver_username_if_known\" will drop this column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('giver_username_if_known',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4040 entries, 0 to 4039\n",
      "Data columns (total 30 columns):\n",
      "number_of_downvotes_of_request_at_retrieval             4040 non-null int64\n",
      "number_of_upvotes_of_request_at_retrieval               4040 non-null int64\n",
      "post_was_edited                                         4040 non-null int64\n",
      "request_id                                              4040 non-null object\n",
      "request_number_of_comments_at_retrieval                 4040 non-null int64\n",
      "request_text                                            4040 non-null object\n",
      "request_text_edit_aware                                 4040 non-null object\n",
      "request_title                                           4040 non-null object\n",
      "requester_account_age_in_days_at_request                4040 non-null float64\n",
      "requester_account_age_in_days_at_retrieval              4040 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_request      4040 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_retrieval    4040 non-null float64\n",
      "requester_number_of_comments_at_request                 4040 non-null int64\n",
      "requester_number_of_comments_at_retrieval               4040 non-null int64\n",
      "requester_number_of_comments_in_raop_at_request         4040 non-null int64\n",
      "requester_number_of_comments_in_raop_at_retrieval       4040 non-null int64\n",
      "requester_number_of_posts_at_request                    4040 non-null int64\n",
      "requester_number_of_posts_at_retrieval                  4040 non-null int64\n",
      "requester_number_of_posts_on_raop_at_request            4040 non-null int64\n",
      "requester_number_of_posts_on_raop_at_retrieval          4040 non-null int64\n",
      "requester_number_of_subreddits_at_request               4040 non-null int64\n",
      "requester_received_pizza                                4040 non-null bool\n",
      "requester_subreddits_at_request                         4040 non-null object\n",
      "requester_upvotes_minus_downvotes_at_request            4040 non-null int64\n",
      "requester_upvotes_minus_downvotes_at_retrieval          4040 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_request             4040 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_retrieval           4040 non-null int64\n",
      "requester_username                                      4040 non-null object\n",
      "unix_timestamp_of_request                               4040 non-null int64\n",
      "unix_timestamp_of_request_utc                           4040 non-null int64\n",
      "dtypes: bool(1), float64(4), int64(19), object(6)\n",
      "memory usage: 919.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Request ID (object columns with probably no value)\n",
    "train.drop('request_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop request raw text, will use request_text_edit_aware to predict\n",
    "train.drop(['request_text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop requester_subreddits_at_request and username\n",
    "train.drop(['requester_subreddits_at_request','requester_username'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have two object data, they are:  \n",
    "1.request_text_edit_aware  \n",
    "2.request_title**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename text and title columns\n",
    "train.rename(columns={\n",
    "    'request_text_edit_aware':'text',\n",
    "    'request_title':'title'  \n",
    "},inplace=True)\n",
    "\n",
    "## Rename text and title columns\n",
    "test.rename(columns={\n",
    "    'request_text_edit_aware':'text',\n",
    "    'request_title':'title'  \n",
    "},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to clean text (stopwords, punct and stemming)\n",
    "\n",
    "def clean(text):\n",
    "    sw = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    no_punc = text.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    no_punc = [word.lower() for word in no_punc.split() if word.lower() not in sw]\n",
    "    \n",
    "    no_stop = \" \".join(no_punc)\n",
    "    \n",
    "    stem = [stemmer.stem(word) for word in no_stop.split()]\n",
    "    \n",
    "    return \" \".join(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply cleaning function on text\n",
    "train['text'] = train['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply function on title\n",
    "train['title'] = train['title'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = train.drop('requester_received_pizza',axis=1)\n",
    "yt = train['requester_received_pizza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(xt['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4040, 9793), (4040,))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.transform(xt['text']).todense()\n",
    "y = yt.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3046\n",
       "True      994\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['requester_received_pizza'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91       763\n",
      "        True       0.98      0.43      0.59       247\n",
      "\n",
      "    accuracy                           0.86      1010\n",
      "   macro avg       0.91      0.71      0.75      1010\n",
      "weighted avg       0.88      0.86      0.84      1010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = vectorizer.transform(test['text']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1631, 9793)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = test[['request_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_sub['requester_received_pizza'] = y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1417\n",
       "1     214\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['requester_received_pizza'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"first-submission-pizza.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 - New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(xt,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(X_train[\"text\"])\n",
    "val_vectors = count_vectorizer.transform(X_val[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2744186 , 0.27826087, 0.30804598])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, y_train, cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                max_iter=None, normalize=False, random_state=None,\n",
       "                solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.81      0.78       758\n",
      "        True       0.28      0.22      0.25       252\n",
      "\n",
      "    accuracy                           0.66      1010\n",
      "   macro avg       0.52      0.52      0.51      1010\n",
      "weighted avg       0.64      0.66      0.65      1010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = count_vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub2 = test[['request_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_sub2['requester_received_pizza'] = pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1456\n",
       "1     175\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub2.requester_received_pizza.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub2.to_csv(\"alternative-submission-pizza.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
